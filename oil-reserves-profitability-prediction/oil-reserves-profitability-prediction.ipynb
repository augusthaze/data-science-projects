{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open files and examine contents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "df_1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "df_2 = pd.read_csv('/datasets/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iJLyR</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>2.978566</td>\n",
       "      <td>168.620776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Xdl7t</td>\n",
       "      <td>1.988431</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>154.036647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
       "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
       "4  Xdl7t  1.988431  0.155413  4.751769  154.036647"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>kBEdx</td>\n",
       "      <td>-15.001348</td>\n",
       "      <td>-8.276000</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>62mP7</td>\n",
       "      <td>14.272088</td>\n",
       "      <td>-3.475083</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>26.953261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vyE1P</td>\n",
       "      <td>6.263187</td>\n",
       "      <td>-5.948386</td>\n",
       "      <td>5.001160</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KcrkZ</td>\n",
       "      <td>-13.081196</td>\n",
       "      <td>-11.506057</td>\n",
       "      <td>4.999415</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AHL4O</td>\n",
       "      <td>12.702195</td>\n",
       "      <td>-8.147433</td>\n",
       "      <td>5.004363</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         f0         f1        f2     product\n",
       "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
       "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
       "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
       "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
       "4  AHL4O  12.702195  -8.147433  5.004363  134.766305"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fwXo0</td>\n",
       "      <td>-1.146987</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>27.758673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WJtFt</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.269839</td>\n",
       "      <td>-2.530187</td>\n",
       "      <td>56.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ovLUW</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-5.586433</td>\n",
       "      <td>62.871910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>q6cA6</td>\n",
       "      <td>2.236060</td>\n",
       "      <td>-0.553760</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>114.572842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WPMUX</td>\n",
       "      <td>-0.515993</td>\n",
       "      <td>1.716266</td>\n",
       "      <td>5.899011</td>\n",
       "      <td>149.600746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
       "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
       "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
       "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
       "4  WPMUX -0.515993  1.716266  5.899011  149.600746"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_0.duplicated().sum())\n",
    "print(df_1.duplicated().sum())\n",
    "print(df_2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first imported the datasets for each region and did some inital exploration of the contents. I also made sure there were no duplicate observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing of data, training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df0 = df_0['product']\n",
    "features_df0 = df_0.drop(['product','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df1 = df_1['product']\n",
    "features_df1 = df_1.drop(['product','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df2 = df_2['product']\n",
    "features_df2 = df_2.drop(['product','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3) (25000, 3)\n",
      "(75000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "features_train_df0, features_valid_df0, target_train_df0, target_valid_df0 = train_test_split(\n",
    "    features_df0, target_df0, test_size=0.25, random_state=12345) \n",
    "\n",
    "print(features_train_df0.shape, features_valid_df0.shape)\n",
    "print(target_train_df0.shape, target_valid_df0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5448279 ,  1.39026372, -0.09495893],\n",
       "       [ 1.4559119 , -0.48042154,  1.20956708],\n",
       "       [ 0.26045969,  0.82506858, -0.2048645 ],\n",
       "       ...,\n",
       "       [ 0.41894874, -1.29678805, -0.19640667],\n",
       "       [ 0.40007671, -1.46687406, -0.44531736],\n",
       "       [ 1.746246  ,  0.02741521,  2.76684795]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(features_train_df0)\n",
    "scaler.transform(features_train_df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3) (25000, 3)\n",
      "(75000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "features_train_df1, features_valid_df1, target_train_df1, target_valid_df1 = train_test_split(\n",
    "    features_df1, target_df1, test_size=0.25, random_state=12345) \n",
    "\n",
    "print(features_train_df1.shape, features_valid_df1.shape)\n",
    "print(target_train_df1.shape, target_valid_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85085526,  0.62442838,  0.29694289],\n",
       "       [ 1.97193524,  1.83227487,  0.29433274],\n",
       "       [ 1.07930536,  0.17012731, -0.29641817],\n",
       "       ...,\n",
       "       [ 1.04707022, -0.64999232,  1.47336769],\n",
       "       [-0.11478048, -1.19069924,  0.29915578],\n",
       "       [-0.64614644,  0.09907453,  0.29561113]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(features_train_df1)\n",
    "scaler.transform(features_train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3) (25000, 3)\n",
      "(75000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "features_train_df2, features_valid_df2, target_train_df2, target_valid_df2 = train_test_split(\n",
    "    features_df2, target_df2, test_size=0.25, random_state=12345) \n",
    "\n",
    "\n",
    "print(features_train_df2.shape, features_valid_df2.shape)\n",
    "print(target_train_df2.shape, target_valid_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52615957,  0.77632883, -0.40079292],\n",
       "       [-0.88962499, -0.4040698 , -1.22293566],\n",
       "       [-1.1339838 ,  0.20857647,  0.2967648 ],\n",
       "       ...,\n",
       "       [ 0.36856367,  0.79722508,  0.66557457],\n",
       "       [-2.44068989,  0.11378427,  0.440907  ],\n",
       "       [-1.73246811,  0.39357329, -1.4244654 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(features_train_df2)\n",
    "scaler.transform(features_train_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare my data, I selected the relevant features, elimnating the `id` column, and established my target value. I also standardized the features I would be using, and split each dataframe into a training a validation set with a 3:1 ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model for each reigon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(features_train, features_valid, target_train, target_valid):\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    predictions = model.predict(features_valid)\n",
    "    correct = target_valid\n",
    "    \n",
    "    return predictions, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average volume of predicted reserves (in thousands of barrels): 92.5926\n",
      "Model RMSE: 37.58\n"
     ]
    }
   ],
   "source": [
    "r1_predictions, r1_correct = train_models(\n",
    "                features_train_df0, features_valid_df0, target_train_df0, target_valid_df0)\n",
    "\n",
    "mse = mean_squared_error(r1_correct, r1_predictions)\n",
    "\n",
    "print('Average volume of predicted reserves (in thousands of barrels): {:.4f}'.format(\n",
    "                                                                        r1_predictions.mean()))\n",
    "print('Model RMSE: {:.2f}'.format(mse ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100000.000000\n",
      "mean         92.500000\n",
      "std          44.288691\n",
      "min           0.000000\n",
      "25%          56.497507\n",
      "50%          91.849972\n",
      "75%         128.564089\n",
      "max         185.364347\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(target_df0.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average volume of predicted reserves (in thousands of barrels): 68.7285\n",
      "Model RMSE: 0.89\n"
     ]
    }
   ],
   "source": [
    "r2_predictions, r2_correct = train_models(\n",
    "                features_train_df1, features_valid_df1, target_train_df1, target_valid_df1)\n",
    "\n",
    "mse = mean_squared_error(r2_correct, r2_predictions)\n",
    "\n",
    "print('Average volume of predicted reserves (in thousands of barrels): {:.4f}'.format(\n",
    "                                                                        r2_predictions.mean()))\n",
    "print('Model RMSE: {:.2f}'.format(mse ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100000.000000\n",
      "mean         68.825000\n",
      "std          45.944423\n",
      "min           0.000000\n",
      "25%          26.953261\n",
      "50%          57.085625\n",
      "75%         107.813044\n",
      "max         137.945408\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(target_df1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average volume of predicted reserves (in thousands of barrels): 94.9650\n",
      "Model RMSE: 40.03\n"
     ]
    }
   ],
   "source": [
    "r3_predictions, r3_correct = train_models(\n",
    "                features_train_df2, features_valid_df2, target_train_df2, target_valid_df2)\n",
    "\n",
    "mse = mean_squared_error(r3_correct, r3_predictions)\n",
    "\n",
    "print('Average volume of predicted reserves (in thousands of barrels): {:.4f}'.format(\n",
    "                                                                        r3_predictions.mean()))\n",
    "print('Model RMSE: {:.2f}'.format(mse ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100000.000000\n",
      "mean         95.000000\n",
      "std          44.749921\n",
      "min           0.000000\n",
      "25%          59.450441\n",
      "50%          94.925613\n",
      "75%         130.595027\n",
      "max         190.029838\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(target_df2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and test my model, I wrote a function that I could use with each region. I then found both the average volume of reserves my model predicted, and the RMSE. Since I found the actual average of each region's target value, I can see that on first glance they look fairly close to the predictions. \n",
    "\n",
    "**Region 1** actual mean is ~92.5001, while the mean for my model's predictions is ~95.5926. \n",
    "\n",
    "**Region 2** actual mean is ~68.8250  and predicted mean is ~68.7285. \n",
    "\n",
    "**Region 3** actual mean is ~95.0004 and predicted mean is ~94.9650. \n",
    "\n",
    "I also found the RMSE, to evaluate how accurately my model was predicting well reserves. Region 2  appears to be the easiest to predict accurately, with an average error equating to <1 unit. Both region 1 and region 3 RMSE is much higher, 37.58 units and 40.03 units, respectively. This value represents somewhere between 170k and 180k USD of revenue, and could mean that projections about well reserves and future profits in these two regions are less reliable. The mathematical descriptions of region 1 and 3 reveal a possible cause of this uncertainty, as there is more dispersion across their reserves compared to region 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for profit calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum reserves required per well to develop without losses, in thousands of barrels:\n",
      "111.11\n"
     ]
    }
   ],
   "source": [
    "BUDGET_PER_WELL = 100000000 / 200 # USD\n",
    "\n",
    "REVENUE_PER_UNIT = 4500 # USD\n",
    "\n",
    "required_reserves = BUDGET_PER_WELL / REVENUE_PER_UNIT\n",
    "\n",
    "print('Minimum reserves required per well to develop without losses, in thousands of barrels:')\n",
    "print('{:.2f}'.format(required_reserves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average volume of reserves, per well (in thousands of barrels)\n",
      "Region 1: 92.50\n",
      "Region 2: 68.83\n",
      "Region 3: 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Average volume of reserves, per well (in thousands of barrels)')\n",
    "print('Region 1: {:.2f}'.format(df_0['product'].mean()))\n",
    "print('Region 2: {:.2f}'.format(df_1['product'].mean()))\n",
    "print('Region 3: {:.2f}'.format(df_2['product'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find how much a well needs to have in its reserves to be profitable or at least break even, I calculated the budget that could be allocated to each well, and divided it by the price per unit. I found that a well would need at least ~111.11 thousand barrels. Comparing this against the average volume per well in each region, it seems possible that regions 1 and 3 are more likely to have wells with sufficient reserves to avoid losses. The mathematical descriptions found earlier backs up this conclusion, as they show that region 2's data points representing each quartile are consistently lower than region 1 and 3. For example, region 2's median is about the same as region 1 and 3's first quartile. So, while it may be easier to accurately predict the reserves in region 2, the overall volume of reserves in the region are significantly lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate profit from selected oil wells and model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 200 highest predicted reserves, by region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_r1 = pd.Series(r1_predictions).sort_values(axis=0, ascending=False)[:200]\n",
    "top_200_r2 = pd.Series(r2_predictions).sort_values(axis=0, ascending=False)[:200]\n",
    "top_200_r3 = pd.Series(r3_predictions).sort_values(axis=0, ascending=False)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.51165419405697\n",
      "138.73013391081713\n",
      "148.01949329159174\n"
     ]
    }
   ],
   "source": [
    "print(top_200_r1.mean())\n",
    "print(top_200_r2.mean())\n",
    "print(top_200_r3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for calculating total profits from development of 200 wells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_profits(targets, predictions):\n",
    "    top = predictions.sort_values(axis=0, ascending=False)[:200]\n",
    "    top_200_target = targets[top.index]\n",
    "    \n",
    "    result = top_200_target.sum() * 4500\n",
    "    return result - 100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total profits from wells selected by top 200 predictions:\n",
      "Region 1: $27686098.34\n",
      "Region 2: $21389816.37\n",
      "Region 3: $25714106.32\n"
     ]
    }
   ],
   "source": [
    "print('Total profits from wells selected by top 200 predictions:')\n",
    "print('Region 1: ${:.2f}'.format(\n",
    "    total_profits(target_df0, pd.Series(model.predict(features_df0)))))\n",
    "print('Region 2: ${:.2f}'.format(\n",
    "    total_profits(target_df1, pd.Series(model.predict(features_df1)))))\n",
    "print('Region 3: ${:.2f}'.format(\n",
    "    total_profits(target_df2, pd.Series(model.predict(features_df2)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 200 wells selected to develop are presumably the ones with the most oil reserves, I found the top 200 predictions (by volume) for each region. I also calculated their respective means to see what the target volume of reserves is when selecting wells to develop, about 140 thousand barrels. The function `total_profits` takes an input of an arbitrary number of wells, finds the top 200 predictions by volume, finds the actual wells that these predictions correspond to, then calculates what the total profit would be from developing them. After this analysis, my initial recommendation for the region to develop is region 1 with the highest profit from its top 200 predicted wells of all three, and the largest average predicted well reserves. However, regions 1 and 3 were also the two with the least accurate predictions, and region 2 is not far behind in total profits for its top 200 predicted wells, so further investigation could indicate otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of risks and profit for each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find distribution of profits with bootstrapped samples from each region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap function to find distribution of profit\n",
    "\n",
    "def bootstrap(df):\n",
    "    region_samples = []\n",
    "    for i in range(1000):\n",
    "        subsample = df.sample(n=500, replace=True, random_state=state)\n",
    "        targets = subsample['product']\n",
    "        predictions = model.predict(subsample[['f0','f1','f2']])\n",
    "        region_samples.append(total_profits(targets, pd.Series(predictions, index=targets.index)))\n",
    "    return region_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_1_profits = pd.Series(bootstrap(df_0))\n",
    "region_2_profits = pd.Series(bootstrap(df_1))\n",
    "region_3_profits = pd.Series(bootstrap(df_2))\n",
    "\n",
    "\n",
    "r1_prf_mean = region_1_profits.mean()\n",
    "r2_prf_mean = region_2_profits.mean()\n",
    "r3_prf_mean = region_3_profits.mean()\n",
    "\n",
    "r1_conf_int = (region_1_profits.quantile(q=0.025), region_1_profits.quantile(q=0.975))\n",
    "r2_conf_int = (region_2_profits.quantile(q=0.025), region_2_profits.quantile(q=0.975))\n",
    "r3_conf_int = (region_3_profits.quantile(q=0.025), region_3_profits.quantile(q=0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total profit of samples and cofidence interval\n",
      "Region 1:\n",
      "3363341.1490838462 (-2288043.605258777, 8600450.30659621)\n",
      "Region 2:\n",
      "4648937.162503721 (529858.3298823935, 9108568.167597998)\n",
      "Region 3:\n",
      "4220104.2371187955 (-1069840.1964871965, 9660332.02093078)\n"
     ]
    }
   ],
   "source": [
    "print('Average total profit of samples and cofidence interval')\n",
    "print('Region 1:')\n",
    "print(r1_prf_mean, r1_conf_int)\n",
    "print('Region 2:')\n",
    "print(r2_prf_mean, r2_conf_int)\n",
    "print('Region 3:')\n",
    "print(r3_prf_mean, r3_conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate risk of losses for each region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of losses for Region 1: 10.100000%\n",
      "Risk of losses for Region 2: 1.700000%\n",
      "Risk of losses for Region 3: 5.300000%\n"
     ]
    }
   ],
   "source": [
    "print('Risk of losses for Region 1: {:%}'.format(np.mean(region_1_profits < 0)))\n",
    "print('Risk of losses for Region 2: {:%}'.format(np.mean(region_2_profits < 0)))\n",
    "print('Risk of losses for Region 3: {:%}'.format(np.mean(region_3_profits < 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyze both the risks and potential profits developing in each region could result in, I wrote a function that used bootstrapping to model 1000 different scenarios for each region. Each sample had 500 wells, selected randomly from the target values of the original datasets, which I passed to the `total_profits` function. This resulted in a list of the profits that each scenario would net, which I could then use to find both an average and a confidence interval for each region. I also found the risk of losses (negative profits) for all three. While region 2 appeared to be potentially less profitable initially, with a lower average volume of reserves and lower predicted profits for the models top 200 predictions, it seems that a model can make much more accurate predictions for this region. The higher profits for region 1 and 3 were a better reflection of how overstated the model's predictions were, rather than actual profitability. The bootstrapping I did to find profit distribution and risk of losses show that region 2 had the highest average profit from 1k samples, and the lowest risk of losses by far. Additionally, region 1 and 3 had negative profits of about -1m and -2.3m respectively within the 95% confidence interval. After this analysis, my final suggestion is to develop region 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
